# ðŸ¦´ FHP Detection System

> **Real-time Forward Head Posture Detection & Correction** using Computer Vision + Deep Learning + Graph Convolutional Networks

![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)
![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)

---

## ðŸŽ¯ What Does This Do?

This system detects **Forward Head Posture (FHP)** â€” a common postural issue where the head juts forward relative to the shoulders â€” using only a webcam. It tracks key anatomical landmarks (head top â†’ ear tragus â†’ neck â†’ shoulder â†’ hand) and uses a **Spatio-Temporal Graph Convolutional Network (ST-GCN)** to classify posture as Normal or FHP in real-time.

### Why GCN Instead of Simple Rules?

Traditional approaches use hardcoded angle thresholds (e.g., CVA < 46Â° = FHP). This fails because:
- Camera angles vary â†’ angles change
- Body proportions differ â†’ thresholds don't generalize
- Single angles miss complex postural patterns

Our **GCN learns from data** â€” it captures the full spatial relationship between connected joints (shoulderâ†’elbowâ†’wrist chain, spineâ†’neckâ†’head chain) and temporal patterns across frames. The result: **genuinely adaptive detection, not predefined rules**.

---

## ðŸ—ï¸ Architecture

```
Webcam â†’ MediaPipe 2D Pose â†’ VideoPose3D (2Dâ†’3D Lift) â†’ Normalization â†’ ST-GCN â†’ FHP/Normal
                                                        â†“
                                              Biomechanical Features
                                              (CVA proxy, angles)
```

| Component | Purpose |
|---|---|
| **MediaPipe Pose** | Real-time 2D keypoint detection (33 landmarks â†’ 17 H36M joints) |
| **VideoPose3D** | Lifts 2D joints to 3D space (pretrained on Human3.6M) |
| **Preprocessing** | Pelvis centering, torso-length scaling, spine alignment |
| **Biomechanical Module** | Computes CVA proxy, shoulder rounding, head displacement |
| **ST-GCN** | Classifies 3D skeleton sequences as Normal/FHP |

---

## ðŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run Real-time Detection
```bash
python src/realtime/app.py --config config.yaml
```
> âš ï¸ First run will use demo mode (random weights). Train a model first for real detection.

### 3. Full Pipeline (Automated)
```bash
# Run the entire data pipeline
python scripts/run_pipeline.py --config config.yaml --stage all

# Or run individual stages:
python scripts/run_pipeline.py --stage collect      # Check raw data
python scripts/run_pipeline.py --stage detect_2d    # 2D pose estimation
python scripts/run_pipeline.py --stage lift_3d      # 2Dâ†’3D lifting
python scripts/run_pipeline.py --stage preprocess   # Normalize
python scripts/run_pipeline.py --stage label        # Interactive labeling
python scripts/run_pipeline.py --stage split        # Train/val/test split
python scripts/run_pipeline.py --stage verify       # Readiness check
```

### 4. Train the Model
```bash
python scripts/train.py --config config.yaml --epochs 200
```

---

## ðŸ“ Project Structure

```
â”œâ”€â”€ config.yaml                  # Master configuration
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py           # PyTorch Dataset + DataLoader
â”‚   â”‚   â”œâ”€â”€ preprocessing.py     # 3D pose normalization
â”‚   â”‚   â”œâ”€â”€ augmentation.py      # 3D skeleton augmentation
â”‚   â”‚   â””â”€â”€ label_tools.py       # Visual labeling guide + tool
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ pose_estimator.py    # MediaPipe wrapper
â”‚   â”‚   â”œâ”€â”€ videopose3d.py       # 2Dâ†’3D lifting
â”‚   â”‚   â””â”€â”€ stgcn.py             # ST-GCN classifier
â”‚   â”œâ”€â”€ realtime/
â”‚   â”‚   â””â”€â”€ app.py               # Real-time webcam app
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ skeleton.py          # Skeleton graph definitions
â”‚       â”œâ”€â”€ angles.py            # Biomechanical computations
â”‚       â””â”€â”€ metrics.py           # Evaluation metrics
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py          # End-to-end automation
â”‚   â””â”€â”€ train.py                 # Training script
â”œâ”€â”€ notebooks/                   # Colab notebooks
â”œâ”€â”€ data/                        # Raw + processed data
â”œâ”€â”€ models/                      # Checkpoints + exports
â””â”€â”€ docs/                        # Labeling guides
```

---

## ðŸ“ Key Anatomical Landmarks

| # | Landmark | Clinical Role |
|---|---|---|
| 1 | **Head Top** | Cranium position tracking |
| 2 | **Ear Tragus** | Gold standard CVA reference point |
| 3 | **Top Neck (C1-C2)** | Upper cervical flexion |
| 4 | **Bottom Neck (C7)** | CVA pivot point |
| 5 | **Shoulder (Acromion)** | Shoulder rounding + alignment |
| 6 | **Wrist/Hand** | Activity context (typing vs phone) |

---

## ðŸ§  Model Details

**Spatio-Temporal GCN (ST-GCN)**:
- **Spatial**: 3-layer GCN respecting skeleton connectivity (13 upper body joints)
- **Temporal**: 2-layer 1D convolution across 30-frame windows
- **Fusion**: Biomechanical features (6 angles) merged with learned embeddings
- **Output**: Binary classification (Normal vs FHP) with confidence score

---

## ðŸ“Š Data Labeling

The labeling tool provides a visual guide and interactive interface. Key rule:

> **If the ear is FORWARD of the shoulder line â†’ FHP. If aligned or behind â†’ Normal.**

Run the labeling tool:
```bash
python -c "from src.data.label_tools import ImageLabeler; ImageLabeler('data/raw').run()"
```

---

## ðŸ“š References

- [PMC: FHP Recognition with GCN](https://pmc.ncbi.nlm.nih.gov/articles/PMC11384178/) â€” GCN-based FHP detection methodology
- [Don't Be Turtle](https://github.com/motlabs/dont-be-turtle) â€” Mobile posture detection project
- [Human3.6M](http://vision.imar.ro/human3.6m) â€” 3.6M 3D human poses dataset
- [VideoPose3D](https://github.com/facebookresearch/VideoPose3D) â€” 3D pose estimation from video

---

## ðŸ“„ License

Apache License 2.0
